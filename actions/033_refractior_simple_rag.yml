source_dir: /Users/allwefantasy/projects/auto-coder
target_file: /Users/allwefantasy/projects/auto-coder/output.txt 
project_type: py

## urls: https://docs.llamaindex.ai/en/stable/examples/query_engine/RouterQueryEngine
urls: /Users/allwefantasy/projects/auto-coder/temp_docs/RouterQueryEngine.txt

model: gpt3_5_chat
index_model: haiku_chat
emb_model: gpt_emb

index_filter_level: 1
index_model_max_input_length: 30000
# index_filter_workers: 2
# enable_rag_context: true

skip_build_index: false
execute: true
## 代码生成的时候会每次生成一个文件，现在大模型无法一次性生成太多文件，所以需要多轮生成
enable_multi_round_generate: true
auto_merge: true
human_as_model: true

query: |
   请阅读 command_args.py，simple_rag.py,common/__init__.py 三个文件的源码。
   按如下要求修改simple_rag.py代码：

   ### 初始化
   去掉
   self.namespace = "default"
   self.chunk_collection = "default"
   
   然后
   self.storage_context 改成 self.storage_contexts 为一个map对象，key为collection，value为storage_context对象。
   self.simple_retrieval 改成 self.simple_retrievals 为一个map对象，key为collection，value为simple_retrieval对象。

   根据 （args.collection或者args.collections） 和 args.description 来初始化 storage_contexts 和 simple_retrievals

   ### build 方法

   build 只允许在 args.collection 有值的情况下执行，否则报错。
   根据 args.collection 来选择 storage_contexts 和 simple_retrievals 中的值。

   ### stream_search/retrieve/stream_chat_oai/stream_chat_repl/search 方法

   只允许在 args.collections 有值的情况下执行，否则报错。
   需要根据 collection 来选择 storage_contexts 和 simple_retrievals 中的值。
   
   如果 args.collections 只有一个值(多个值会按逗号分隔)，则按原有逻辑执行。
   如果 args.collections 有多个值,并且args.description没有值的时候，则按照顺序执行。
   如果 args.collections 有多个值,并且args.description有值的时候，则参考 RouterQueryEngine.txt 文档中的描述，用 QueryEngineTool 将
   各个 query_engine 转换为tool, RouterQueryEngine 来形成一个新的 query_engine,然后使用新的 query_engine 来执行。

   一个小tips, 可以抽象出一个方法，来完成完成上面的逻辑，返回合适的query_engine, 然后在 stream_search/retrieve/stream_chat_oai/stream_chat_repl/search 方法中调用这个方法。

   
    
   
   




   
